{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.datasets import mnist\n",
    "(X_train, Y_train), (X_test, Y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MNIST Dataset Shape:\n",
      "X_train:  (60000, 28, 28)\n",
      "Y_train:  (60000,)\n",
      "X_test:   (10000, 28, 28)\n",
      "Y_test:   (10000,)\n"
     ]
    }
   ],
   "source": [
    "print('MNIST Dataset Shape:')\n",
    "print('X_train: ', str(X_train.shape))\n",
    "print('Y_train: ', str(Y_train.shape))\n",
    "print('X_test:  ', str(X_test.shape))\n",
    "print('Y_test:  ', str(Y_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-0.5, 27.5, 27.5, -0.5)"
      ]
     },
     "execution_count": 245,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "img_size = 28\n",
    "plt.subplot(1,2,1)\n",
    "plt.imshow(X_train[10].reshape(img_size, img_size))\n",
    "plt.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MNIST Dataset Shape:\n",
      "xTrain:  (18623, 28, 28)\n",
      "yTrain:  (18623,)\n"
     ]
    }
   ],
   "source": [
    "train_filter = np.where((Y_train == 0 ) | (Y_train == 1) | (Y_train == 2))\n",
    "test_filter = np.where((Y_test == 0) | (Y_test == 1) | (Y_test == 2) )\n",
    "xTrain, yTrain = X_train[train_filter], Y_train[train_filter]\n",
    "xTest, yTest = X_test[test_filter], Y_test[test_filter]\n",
    "\n",
    "print('MNIST Dataset Shape:')\n",
    "print('xTrain: ', str(xTrain.shape))\n",
    "print('yTrain: ', str(yTrain.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape :  (18623, 784)\n",
      "Shape :  (3147, 784)\n"
     ]
    }
   ],
   "source": [
    "x_train = xTrain.reshape(xTrain.shape[0], xTrain.shape[1] * xTrain.shape[2])\n",
    "x_test = xTest.reshape(xTest.shape[0], xTest.shape[1] * xTest.shape[2])\n",
    "print('Shape : ', x_train.shape)\n",
    "print('Shape : ', x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xTrain shape :  (784, 18623)\n",
      "yTrain shape :  (18623, 1)\n"
     ]
    }
   ],
   "source": [
    "xTrain = x_train.T\n",
    "yTrain = yTrain.reshape(18623,1)\n",
    "\n",
    "print('xTrain shape : ', xTrain.shape)\n",
    "print('yTrain shape : ', yTrain.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [],
   "source": [
    "#enc = preprocessing.OneHotEncoder()\n",
    "# 2. FIT\n",
    "#enc.fit(yTrain)\n",
    "# 3. Transform\n",
    "#onehotlabels = enc.transform(yTrain).toarray()\n",
    "#onehotlabels.shape#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [],
   "source": [
    "#y_enc = (np.arange(np.max(yTrain) + 1) == yTrain[:, None]).astype(float)\n",
    "#print('one-hot encoding:\\n', y_enc.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(784, 3)\n"
     ]
    }
   ],
   "source": [
    "w = np.full((784,3), 0.001)\n",
    "print(w.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [],
   "source": [
    "#scores = np.dot(w.T,x_Train)\n",
    "#print(scores.shape)\n",
    "#prob = softmax(scores)\n",
    "#print(np.log(prob.T))\n",
    "#print(prob.shape)\n",
    "#print(yTrain.shape)\n",
    "#print((yTrain - prob).shape)\n",
    "#print(x_Train.shape)\n",
    "#loss = (-1 / y_enc.shape[0]) * np.sum(np.mat(y_enc.shape[0]) * np.log(prob)) + (1/2)*np.sum(w*w)\n",
    "#loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#(((-1 / yTrain.shape[0]) * np.dot(x_Train,(yTrain - prob.T)) ) + (0.1)*w).shape\n",
    "#loss = (-1 / yTrain.shape[0]) * np.sum(np.mat(yTrain) * np.log(prob)) + (0.1/2) * np.sum(w*w)\n",
    "#loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(z):\n",
    "    z -= np.max(z)\n",
    "    sm = (np.exp(z).T / np.sum(np.exp(z),axis=1)).T\n",
    "    return sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [],
   "source": [
    "#z = softmax(scores)\n",
    "#print(z)\n",
    "#yTrain.shape[0]\n",
    "#xTrain.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getLoss(w,xTrain,yTrain,lam):\n",
    "    scores = np.dot(w.T,xTrain)#Then we compute raw class scores given our input and current weights\n",
    "    enc = preprocessing.OneHotEncoder()\n",
    "    enc.fit(yTrain)\n",
    "    y = enc.transform(yTrain).toarray()\n",
    "    prob = softmax(scores) #Next we perform a softmax on these scores to get their probabilities\n",
    "    loss = -1 * np.sum(yTrain.T * np.log(prob))\n",
    "    #loss = (-1 / yTrain.shape[0]) * np.sum(np.mat(y.T) * np.log(prob.T)) + (lam/2)*np.sum(w*w) #We then find the loss of the probabilities\n",
    "    grad = (-1 / yTrain.shape[0]) * np.dot(xTrain,(y - prob.T)) + lam*w #And compute the gradient for that loss\n",
    "    return loss,grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loss,grad = getLoss(w,x_Train,yTrain,lam = 0.1)\n",
    "#print('loss : ', loss)\n",
    "#print('grad : ', grad)\n",
    "#print(grad.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w :  [nan nan nan]\n",
      "grad :  [nan nan nan]\n",
      "loss :  nan\n",
      "w :  [nan nan nan]\n",
      "grad :  [nan nan nan]\n",
      "loss :  nan\n",
      "w :  [nan nan nan]\n",
      "grad :  [nan nan nan]\n",
      "loss :  nan\n",
      "w :  [nan nan nan]\n",
      "grad :  [nan nan nan]\n",
      "loss :  nan\n",
      "w :  [nan nan nan]\n",
      "grad :  [nan nan nan]\n",
      "loss :  nan\n"
     ]
    }
   ],
   "source": [
    "losses = []\n",
    "iterations = 5\n",
    "learningRate = 0.1\n",
    "for i in range(iterations):\n",
    "    loss,grad = getLoss(w,xTrain,yTrain,lam = 0.1)\n",
    "    losses.append(loss)\n",
    "    w = w - (learningRate * grad)\n",
    "#    if w.any() < 0:\n",
    "#        w = -w\n",
    "#    else:\n",
    "#        w\n",
    "    print('w : ',w[2])\n",
    "    print('grad : ',grad[2])\n",
    "    print('loss : ',loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
